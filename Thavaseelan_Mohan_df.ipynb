{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7f6859-a3a9-41c4-b0d4-bc9fe3e20db7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## DATAFRAME IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfeb560f-cbd1-4882-a125-19c79f3141fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[2]: '\\n%run\\n./Thavaseelan_Mohan_rdd\\n'"
     ]
    }
   ],
   "source": [
    "## This script will automaticall fetch and execute the variables and functions from another notebook\n",
    "\"\"\"\n",
    "%run\n",
    "./Thavaseelan_Mohan_rdd\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "168c3f6d-e5b5-4736-9786-a6c58f482d0b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Import required libraries and preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "843c5b05-f0db-4598-928e-859600d6c16a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clinicaltrial_2023 loaded successfully!!!\npharma loaded successfully!!!\nSource data converted to RDD Successfully!!!\nDataframe created for source file\nData Splitted and Cleansing done Successfully!!!\nDataframe created for cleansed file\nRDD for clinical cleansed data created successfully!!!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "import re\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "Source_file1='clinicaltrial_2023'\n",
    "Source_file2='pharma'\n",
    "Source_zip_format_extension='.zip'\n",
    "Source_file_format='.csv'\n",
    "\n",
    "#def split_file():\n",
    "delimiters1=[\"\\t\"]\n",
    "df_clinical=spark.read.csv(\"/FileStore/tables/\" + Source_file1 + Source_file_format,\n",
    "                           sep=delimiters1,\n",
    "                           header=True,\n",
    "                           inferSchema=True)\n",
    "    \n",
    "rdd_clinical=df_clinical.rdd\n",
    "\n",
    "print(f\"{Source_file1} loaded successfully!!!\")\n",
    "    \n",
    "df_Pharma=spark.read.csv(\"/FileStore/tables/\" + Source_file2 + Source_file_format,\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True)\n",
    "df_Pharma_rdd=df_Pharma.rdd\n",
    "print(f\"{Source_file2} loaded successfully!!!\")\n",
    "#split_file()\n",
    "\n",
    "#def create_dataframe():\n",
    "Schema = StructType([\n",
    "        StructField(\"Id\", StringType()),\n",
    "        StructField(\"StudyTitle\", StringType()),\n",
    "        StructField(\"Acronym\", StringType()),\n",
    "        StructField(\"Status\", StringType()),\n",
    "        StructField(\"Conditions\", StringType()),\n",
    "        StructField(\"Interventions\", StringType()),\n",
    "        StructField(\"Sponsor\", StringType()),\n",
    "        StructField(\"Collaborators\", StringType()),\n",
    "        StructField(\"Enrollment\", StringType()),\n",
    "        StructField(\"FunderType\", StringType()),\n",
    "        StructField(\"Type\", StringType()),\n",
    "        StructField(\"StudyDesign\", StringType()),\n",
    "        StructField(\"Start\", StringType()),\n",
    "        StructField(\"Completion\", StringType())\n",
    "        ])\n",
    "\n",
    "RDD_raw = rdd_clinical.map(lambda x : (x[0].split('\\t')))\\\n",
    "                     .map(lambda x : (x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[-7],x[-6],x[-5],x[-4],x[-3],x[-2],x[-1]))\\\n",
    "                     .collect()\n",
    "print(\"Source data converted to RDD Successfully!!!\")\n",
    "\n",
    "Source_Raw = spark.createDataFrame(RDD_raw, Schema)\n",
    "Raw_file=sc.parallelize(RDD_raw)\n",
    "df_raw=Raw_file.toDF()\n",
    "print(\"Dataframe created for source file\")\n",
    "\n",
    "RDD_cleansed = rdd_clinical.map(lambda x : (x[0].replace('\\\"','').replace(',','').split('\\t')))\\\n",
    "                           .filter(lambda x : x[0] is not None)\\\n",
    "                           .filter(lambda x : x[0]!='')\\\n",
    "                           .filter(lambda x : (x[0]!='NCT00146315'))\\\n",
    "                           .filter(lambda x : len(x[0])<=11)\\\n",
    "                           .map(lambda x : (x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8],x[9],x[10],x[11],x[12],x[13]))\\\n",
    "                           .collect()\n",
    "print(\"Data Splitted and Cleansing done Successfully!!!\")\n",
    "Source_Transform = spark.createDataFrame(RDD_cleansed, Schema)\n",
    "Transf=sc.parallelize(RDD_cleansed)\n",
    "df_main=Transf.toDF()\n",
    "print(\"Dataframe created for cleansed file\")\n",
    "\n",
    "Final_rdd=df_main.rdd\n",
    "print(\"RDD for clinical cleansed data created successfully!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fb24ca3-de14-4e74-bab1-a721cf724912",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Scenario 1 - The number of studies in the dataset. You must ensure that you explicitly check distinct studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27313bfc-2232-4f0e-a720-431b8d2c2cb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of distinct studies count is: 483420\n"
     ]
    }
   ],
   "source": [
    "def DataFrame_SC1_Distinct_Studies():\n",
    "    \n",
    "    Studies_count=Source_Transform.select(\"Id\").dropDuplicates().distinct().count()\n",
    "                                   \n",
    "    print(\"Total no of distinct studies count is:\",  Studies_count)\n",
    "\n",
    "DataFrame_SC1_Distinct_Studies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f481be3-6081-4a0a-8dc8-746bc4f2f8a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Scenario 2 - You should list all the types (as contained in the Type column) of studies in the dataset along with the frequencies of each type. These should be ordered from most frequent to least frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f9c79fb-db25-45e6-9d01-2969f5594453",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+\n|Type           |Count |\n+---------------+------+\n|INTERVENTIONAL |371382|\n|OBSERVATIONAL  |110221|\n|EXPANDED_ACCESS|928   |\n|               |889   |\n+---------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "def DataFrame_SC2_StudyType_Groupwise():\n",
    "\n",
    "    StudyType_Group = Source_Transform.select(\"Id\",\"Type\")\\\n",
    "                                      .groupBy(trim((\"Type\")).alias(\"Type\"))\\\n",
    "                                      .agg(count(\"Type\").alias(\"Count\"))\n",
    "\n",
    "    StudyType_Group.show(truncate=False)\n",
    "\n",
    "DataFrame_SC2_StudyType_Groupwise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ba2cbfc-810f-4825-b6e0-e6bc924a4156",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Scenario 3 - The top 5 conditions (from Conditions) with their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5093d676-85c4-4255-b130-348461506b4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----+----+\n|Conditions_transformed|Coun|rank|\n+----------------------+----+----+\n|Healthy               |9731|1   |\n|Breast Cancer         |7502|2   |\n|Obesity               |6549|3   |\n|Stroke                |4073|4   |\n|Hypertension          |4024|5   |\n|Depression            |3911|6   |\n+----------------------+----+----+\n\n"
     ]
    }
   ],
   "source": [
    "def DataFrame_SC3_Conditions_Frequencies():\n",
    "\n",
    "    Conditions_Frequency = Source_Transform.select(\"Id\",explode(split(\"Conditions\",\"\\\\|\")).alias(\"Conditions\"))\\\n",
    "                                        .filter(\"Conditions is not null\")\\\n",
    "                                        .groupBy(trim((\"Conditions\")).alias(\"Conditions_transformed\"))\\\n",
    "                                           .agg(count(\"Conditions\").alias(\"Coun\"))\\\n",
    "                                           .sort(\"Coun\")\\\n",
    "    \n",
    "    Order_Window = Window.orderBy(Conditions_Frequency['Coun'].desc())\n",
    "\n",
    "    cf=Conditions_Frequency.select('*', dense_rank().over(Order_Window).alias('rank'))\\\n",
    "                           .filter(col('rank') <= 6)\n",
    "\n",
    "    result = cf.show(truncate=False)\n",
    "\n",
    "DataFrame_SC3_Conditions_Frequencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd1916b0-463a-478d-a7a6-0e05037ff581",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Scenario 4 - Find the 10 most common sponsors that are not pharmaceutical companies, along with the number of clinical trials they have sponsored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b5b1d3c-8610-4c78-85ed-bb65dd05160b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+----+\n|Sponsor                                                      |Coun|\n+-------------------------------------------------------------+----+\n|National Cancer Institute (NCI)                              |3410|\n|Assiut University                                            |3335|\n|Cairo University                                             |3023|\n|Assistance Publique - HÃ´pitaux de Paris                      |2951|\n|Mayo Clinic                                                  |2766|\n|M.D. Anderson Cancer Center                                  |2702|\n|Novartis Pharmaceuticals                                     |2393|\n|National Institute of Allergy and Infectious Diseases (NIAID)|2340|\n|Massachusetts General Hospital                               |2263|\n|National Taiwan University Hospital                          |2181|\n+-------------------------------------------------------------+----+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "def DataFrame_SC4_Non_Common_sponsors_Trials():\n",
    "    \n",
    "    Required_Fields = Source_Transform.select(trim(\"Sponsor\").alias(\"Sponsor\") ,\"Id\")\\\n",
    "                                      .distinct()\n",
    "                                    \n",
    "    Clincal_data = Source_Transform.select(trim(\"Sponsor\").alias(\"Sponsor_Clinical\"))\\\n",
    "                                   .filter(\"Sponsor_Clinical is not null\")\\\n",
    "                                   .filter(trim(\"Sponsor_Clinical\")!='')\\\n",
    "                                   .distinct()\n",
    "                                 \n",
    "    Pharmacy_data = df_Pharma.select(trim(\"Parent_Company\").alias(\"Parent_Company_Pharma\"))\\\n",
    "                             .filter(\"Parent_Company_Pharma is not null\")\\\n",
    "                             .filter(trim(\"Parent_Company_Pharma\")!='')\\\n",
    "                             .distinct()\n",
    "                           \n",
    "    Non_Common_Pharamcy = Clincal_data.exceptAll(Pharmacy_data)\\\n",
    "                                      .select(Clincal_data[\"Sponsor_Clinical\"])\n",
    "                                    \n",
    "    jn = Required_Fields.join(Non_Common_Pharamcy,Required_Fields[\"Sponsor\"]==Non_Common_Pharamcy[\"Sponsor_Clinical\"],\"inner\")\\\n",
    "                        .select(Required_Fields[\"Sponsor\"],Required_Fields[\"Id\"])\\\n",
    "                        .groupBy(\"Sponsor\")\\\n",
    "                        .agg(count(\"Sponsor\")\\\n",
    "                        .alias(\"Coun\"))\n",
    "\n",
    "    Non_Pharma_Trials = jn.sort(jn.Coun.desc())\\\n",
    "                          .show(10,truncate=False)\n",
    "\n",
    "\n",
    "DataFrame_SC4_Non_Common_sponsors_Trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9a57607-e9de-4d6c-a2b9-df4e79663d50",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Scenario 5 - Plot number of completed studies for each month in 2023. You need to include your visualization as well as a table of all the values you have plotted for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "456614c2-558a-4484-beea-fd6d96ae6d31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n|    Month|Count|\n+---------+-----+\n|      Jan| 1494|\n|      Feb| 1272|\n|      Mar| 1552|\n|      Apr| 1324|\n|      May| 1415|\n|     June| 1619|\n|     July| 1360|\n|   August| 1230|\n|September| 1152|\n|  October| 1058|\n| November|  909|\n| December| 1082|\n+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "def DataFrame_SC5_Completed_Status_Monthwise():\n",
    "\n",
    "    Final = Source_Transform.filter(lower(\"Status\")==\"completed\")\\\n",
    "                            .filter(year(to_date(\"Completion\"))=='2023')\\\n",
    "                            .select(\"Id\",\"Completion\",to_date(trim(\"Completion\")).alias(\"Date-Format\"),year(to_date(trim(\"Completion\"))).alias(\"Year\"),\n",
    "                                    lpad(month(to_date(trim(\"Completion\"))),2,'0').alias(\"Month\"))\\\n",
    "                            .groupBy(lpad(month(to_date(trim(\"Completion\"))),2,'0').alias(\"Month\"))\\\n",
    "                            .agg(count(lpad(month(to_date(trim(\"Completion\"))),2,'0')).alias(\"Count\"))\\\n",
    "                            .sort(\"Month\").replace('01','Jan').replace('02','Feb').replace('03','Mar').replace('04','Apr').replace('05','May').\\\n",
    "                            replace('06','June').replace('07','July').replace('08','August').replace('09','September').replace('10','October').\\\n",
    "                            replace('11','November').replace('12','December')\\\n",
    "                            .show()\n",
    "\n",
    "DataFrame_SC5_Completed_Status_Monthwise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a33af18-bace-44c3-84c9-5296e68c520e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Additional Negative Scenario - TO find Members with Completion status with future datespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac40d73-48d0-4207-bc15-4a9b52965cd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Year</th><th>Status</th><th>Count</th></tr></thead><tbody><tr><td>2024</td><td>COMPLETED</td><td>622</td></tr><tr><td>2031</td><td>COMPLETED</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2024,
         "COMPLETED",
         622
        ],
        [
         2031,
         "COMPLETED",
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Year",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Status",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def DataFrame_Addition_Negative_Scenario():\n",
    "\n",
    "    Final = Source_Transform.filter(lower(\"Status\")==\"completed\")\\\n",
    "                            .filter(year(to_date(trim(\"Completion\")))>'2023')\\\n",
    "                            .select(\"Id\",\"Status\",\"Completion\",to_date(\"Completion\").alias(\"Date-Format\"),year(to_date(\"Completion\")).alias(\"Year\")).groupBy(\"Year\",\"Status\")\\\n",
    "                            .agg(count(\"Status\").alias(\"Count\"))\\\n",
    "                            .sort(\"Year\")\\\n",
    "                            .display()\n",
    "                            \n",
    "DataFrame_Addition_Negative_Scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6930966c-ddb7-4bfc-9ff8-130c220eeb2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------------------------------------------------------------------+----------+-----------+----+\n|Id         |Status   |Conditions                                                               |Completion|Date-Format|Year|\n+-----------+---------+-------------------------------------------------------------------------+----------+-----------+----+\n|NCT00888160|COMPLETED|Unstable Pelvic Ring Fracture|Unstable Acetabulum Fracture|Femur Fracture|2031-01   |2031-01-01 |2031|\n|NCT06055088|COMPLETED|Breast Cancer|Neuropathy                                                 |2024-02-16|2024-02-16 |2024|\n|NCT06129721|COMPLETED|Acute Stroke|Ischemic Stroke Acute|Vertebro Basilar Ischemia             |2024-02-16|2024-02-16 |2024|\n|NCT06197659|COMPLETED|Postoperative Nausea and Vomiting                                        |2024-02-15|2024-02-15 |2024|\n|NCT06226207|COMPLETED|Reliability and Validity                                                 |2024-02-15|2024-02-15 |2024|\n|NCT06004921|COMPLETED|Cancer                                                                   |2024-02-15|2024-02-15 |2024|\n|NCT03414905|COMPLETED|Malignant Pleural Effusion                                               |2024-02-15|2024-02-15 |2024|\n|NCT05437003|COMPLETED|Idiopathic Parkinson Disease                                             |2024-02-15|2024-02-15 |2024|\n|NCT05772715|COMPLETED|Thumb Osteoarthritis                                                     |2024-02-15|2024-02-15 |2024|\n|NCT04559802|COMPLETED|Tooth Loss                                                               |2024-02-15|2024-02-15 |2024|\n|NCT03705559|COMPLETED|Marijuana Usage|Opioid Use                                               |2024-02-15|2024-02-15 |2024|\n|NCT05249985|COMPLETED|Spinal Cord Injuries                                                     |2024-02-15|2024-02-15 |2024|\n|NCT06065488|COMPLETED|Foot Ulcer                                                               |2024-02-14|2024-02-14 |2024|\n|NCT05892094|COMPLETED|Hot Flashes|Menopause                                                    |2024-02-14|2024-02-14 |2024|\n|NCT06129773|COMPLETED|Surgical Site Infection                                                  |2024-02-14|2024-02-14 |2024|\n|NCT06060223|COMPLETED|Heart Failure                                                            |2024-02-14|2024-02-14 |2024|\n|NCT05713032|COMPLETED|Lumbar Radiculopathy                                                     |2024-02-14|2024-02-14 |2024|\n|NCT02224469|COMPLETED|Locked-In Syndrome                                                       |2024-02-14|2024-02-14 |2024|\n|NCT05686044|COMPLETED|Alzheimer Disease                                                        |2024-02-13|2024-02-13 |2024|\n|NCT05893706|COMPLETED|Osteo Arthritis Knee                                                     |2024-02-13|2024-02-13 |2024|\n+-----------+---------+-------------------------------------------------------------------------+----------+-----------+----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "Final = Source_Transform.filter(lower(\"Status\")==\"completed\")\\\n",
    "                            .filter(year(to_date(trim(\"Completion\")))>'2023')\\\n",
    "                            .select(\"Id\",\"Status\",\"Conditions\",\"Completion\",to_date(\"Completion\").alias(\"Date-Format\"),year(to_date(\"Completion\")).alias(\"Year\"))\\\n",
    "                            .sort(\"Completion\",ascending=False)\\\n",
    "                            .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95455206-a5cc-4fea-ac07-af7974535615",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4057127938025080,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Thavaseelan_Mohan_df",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
